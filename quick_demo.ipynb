{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Demonstrating generalized kalman filter by backprop\n",
    "\n",
    "TODO:\n",
    "- support learning from a batch of time-series \n",
    "  currently the code only supports learning from one time-series. it can support multiple time-series, but it'll be slow.\n",
    "- better optimizer\n",
    "  inference doesn't really work well. using a better optimizer will definitely help.\n",
    "- test with nonlinear KF\n",
    "  only tested with linear KF but the code naturally supports nonlinear KF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import distributions\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GKF(nn.Module):\n",
    "    \n",
    "    def __init__(self, x_dim, h_dim): \n",
    "        super(GKF, self).__init__()\n",
    "        \n",
    "        # we assume an identity covariance in p(x_t|h_t) and p(h_t|h_{t-1})\n",
    "        self.transition = nn.Linear(h_dim, h_dim)\n",
    "        self.emission = nn.Linear(h_dim, x_dim)\n",
    "        self.initial = nn.Parameter(torch.zeros(h_dim))\n",
    "        \n",
    "        self.h_dim = h_dim\n",
    "        self.x_dim = x_dim\n",
    "        \n",
    "    def joint_likelihood(self, x, z):\n",
    "        assert type(x) == list, 'x must be a list of vectors'\n",
    "        assert type(z) == list, 'z must be a list of vectors'\n",
    "        assert len(x)+1 == len(z), 'z must have one more element than x does'\n",
    "        \n",
    "        T = len(x)\n",
    "        \n",
    "        logp = self._compute_normal_log_p(z[0], self.initial, torch.ones(self.h_dim))\n",
    "        \n",
    "        for t in range(T):\n",
    "            mu_z = self.transition(z[t])\n",
    "            logp += self._compute_normal_log_p(z[t+1], mu_z, torch.ones(self.h_dim))\n",
    "            mu_x = self.emission(z[t+1])\n",
    "            logp += self._compute_normal_log_p(x[t], mu_x, torch.ones(self.x_dim))\n",
    "            \n",
    "        return logp\n",
    "    \n",
    "    def emit(self, z_list, sample=False):\n",
    "        x_list = []\n",
    "        \n",
    "        for z in z_list:\n",
    "            mu_x = self.emission(z)\n",
    "            if sample:\n",
    "                x = distributions.normal.Normal(mu_x, torch.ones(self.x_dim)).sample()\n",
    "            else:\n",
    "                x = mu_x\n",
    "            x_list.append(x)\n",
    "            \n",
    "        return x_list\n",
    "            \n",
    "    def sample(self, T, z0=None):\n",
    "        if z0 is None:\n",
    "            z0 = distributions.normal.Normal(self.initial, torch.ones(self.h_dim)).sample()\n",
    "            \n",
    "        z_list = [z0]\n",
    "        z = z0\n",
    "        \n",
    "        for t in range(T):\n",
    "            mu_z = self.transition(z)\n",
    "            z = distributions.normal.Normal(mu_z, torch.ones(self.h_dim)).sample()\n",
    "            z_list.append(z)\n",
    "\n",
    "        x_list = self.emit(z_list[1:], sample=True)\n",
    "            \n",
    "        return x_list, z_list\n",
    "        \n",
    "    def _compute_normal_log_p(self, x, mu, diag_cov):\n",
    "        return (-(((x - mu) ** 2) / diag_cov) - torch.log(numpy.sqrt(2.) * torch.sqrt(diag_cov))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GKFQ(nn.Module):\n",
    "    def __init__(self, h_dim, T):\n",
    "        super(GKFQ, self).__init__()\n",
    "        \n",
    "        self.diag_cov = nn.ParameterList()\n",
    "        self.mean = nn.ParameterList()\n",
    "        \n",
    "        for t in range(T):\n",
    "            self.diag_cov.append(nn.Parameter(torch.zeros(h_dim)))\n",
    "            self.mean.append(nn.Parameter(torch.zeros(h_dim)))\n",
    "            \n",
    "        self.T = T\n",
    "        self.h_dim = h_dim\n",
    "        \n",
    "    def sample(self):\n",
    "        samples = []\n",
    "        \n",
    "        for t in range(self.T):\n",
    "            ss = distributions.normal.Normal(self.mean[t], torch.sqrt(torch.exp(self.diag_cov[t]))).rsample()\n",
    "            samples.append(ss)\n",
    "            \n",
    "        return samples\n",
    "    \n",
    "    def compute_log_p(self, z_list):\n",
    "        log_ps = []\n",
    "        for t in range(self.T):\n",
    "            log_ps.append(distributions.normal.Normal(self.mean[t], torch.sqrt(torch.exp(self.diag_cov[t]))).log_prob(z_list[t]))\n",
    "        return log_ps\n",
    "    \n",
    "    def compute_entropy(self):\n",
    "        entropy = 0.\n",
    "        for t in range(self.T):\n",
    "            entropy += distributions.normal.Normal(self.mean[t], torch.sqrt(torch.exp(self.diag_cov[t]))).entropy().sum()\n",
    "        return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 2\n",
    "h_dim = 2\n",
    "T = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf_target = GKF(x_dim, h_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_list, z_list = gkf_model.sample(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' inference '''\n",
    "gkf_model = GKF(x_dim, h_dim)\n",
    "q_model = GKFQ(h_dim, len(x_list)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(itertools.chain(q_model.parameters(), gkf_model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss  96.9422607421875\n",
      "loss  72.27911376953125\n",
      "loss  63.01311111450195\n",
      "loss  58.87183380126953\n",
      "loss  56.976463317871094\n",
      "loss  56.40394973754883\n",
      "loss  54.90300369262695\n",
      "loss  55.34176254272461\n",
      "loss  55.50751495361328\n",
      "loss  54.84132766723633\n",
      "loss  55.342041015625\n",
      "loss  55.46296310424805\n",
      "loss  54.6760368347168\n",
      "loss  54.62382888793945\n",
      "loss  55.1097297668457\n",
      "loss  54.8911247253418\n",
      "loss  55.161338806152344\n",
      "loss  54.46751022338867\n",
      "loss  55.76375198364258\n",
      "loss  56.20075988769531\n",
      "loss  55.401947021484375\n",
      "loss  55.84090042114258\n",
      "loss  55.509742736816406\n",
      "loss  55.34404373168945\n",
      "loss  54.98444366455078\n",
      "loss  54.99190139770508\n",
      "loss  56.105613708496094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-371-1ca66ad2e204>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mz_inferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgkf_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoint_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_inferred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrunning_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-220-0167e7dcf8da>\u001b[0m in \u001b[0;36mjoint_likelihood\u001b[0;34m(self, x, z)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mmu_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mlogp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_normal_log_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mmu_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1408\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = None\n",
    "\n",
    "n_iter = 10000\n",
    "disp_int = 100\n",
    "n_samples = 5\n",
    "entropy_beta = 1.\n",
    "\n",
    "for ni in range(n_iter):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = 0.\n",
    "    for si in range(n_samples):\n",
    "        z_inferred = q_model.sample()\n",
    "        loss = loss - gkf_model.joint_likelihood(x_list, z_inferred)\n",
    "    loss = loss / n_samples\n",
    "    if running_loss is None:\n",
    "        running_loss = loss\n",
    "    else:\n",
    "        running_loss = 0.9 * running_loss + 0.1 * loss\n",
    "    if numpy.mod(ni+1, disp_int) == 0:\n",
    "        print('loss ', running_loss.item())\n",
    "    loss = loss - entropy_beta * q_model.compute_entropy()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(q_model.parameters())[0].grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_list = q_model.mean\n",
    "r_list = gkf_model.emit(q_list[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd688818e43546ada7bbf3c38f647463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_list_ = numpy.array([x.numpy() for x in x_list])\n",
    "z_list_ = numpy.array([z.numpy() for z in z_list])\n",
    "\n",
    "r_list_ = numpy.array([r.detach().numpy() for r in r_list])\n",
    "q_list_ = numpy.array([m.detach().numpy() for m in q_list])\n",
    "\n",
    "plot.figure()\n",
    "\n",
    "plot.subplot(1,2,1)\n",
    "plot.plot(x_list_[:,0], x_list_[:,1], 'b-')\n",
    "for i, x in enumerate(x_list_):\n",
    "    plot.text(x[0], x[1], '{}'.format(i), color='b')\n",
    "    \n",
    "plot.plot(r_list_[:,0], r_list_[:,1], 'r--')\n",
    "for i, r in enumerate(r_list_):\n",
    "    plot.text(r[0], r[1], '{}'.format(i), color='r')\n",
    "\n",
    "plot.subplot(1,2,2)\n",
    "plot.plot(z_list_[:,0], z_list_[:,1], 'b-')\n",
    "for i, z in enumerate(z_list_):\n",
    "    plot.text(z[0], z[1], '{}'.format(i), color='b')\n",
    "plot.plot(q_list_[:,0], q_list_[:,1], 'r--')\n",
    "for i, q in enumerate(q_list_):\n",
    "    plot.text(q[0], q[1], '{}'.format(i), color='r')\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3850859c761c4628a21142b1543bbb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot.figure()\n",
    "\n",
    "plot.subplot(2,1,1)\n",
    "plot.imshow(x_list_.T)\n",
    "plot.colorbar()\n",
    "\n",
    "plot.subplot(2,1,2)\n",
    "plot.imshow(r_list_.T)\n",
    "plot.colorbar()\n",
    "\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 2)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
